{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/pogscafe/invokeai-notebook?scriptVersionId=170933328\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# InvokeAI 3\n\nThis notebook installs and runs the InvokeAI 3 web UI.\n\nGithub link: https://github.com/wandaweb/InvokeAI-Kaggle  \n\nInvokeAI on Github: https://github.com/invoke-ai/InvokeAI","metadata":{}},{"cell_type":"markdown","source":"### Installing InvokeAI - Required","metadata":{}},{"cell_type":"code","source":"import os\nimport subprocess\n\nenv = os.environ.copy()\n\n!pip install pillow==9.5.0 requests==2.31.0 xformers==0.0.20 triton==2.0.0\n!pip install git+https://github.com/openai/CLIP.git@main#egg=clip\n!pip install git+https://github.com/Birch-san/k-diffusion.git@mps#egg=k-diffusion\n!pip install git+https://github.com/invoke-ai/clipseg.git@relaxed-python-requirement#egg=clipseg\n!pip install git+https://github.com/invoke-ai/PyPatchMatch@0.1.4#egg=pypatchmatch\n!pip install 'InvokeAI[xformers]==3.6.0' --use-pep517 --extra-index-url https://download.pytorch.org/whl/cu118\n!pip install --force-reinstall numpy\n\n!mamba install openssh -y \n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-08T08:01:34.33296Z","iopub.execute_input":"2024-04-08T08:01:34.333589Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pillow==9.5.0 in /opt/conda/lib/python3.10/site-packages (9.5.0)\nRequirement already satisfied: requests==2.31.0 in /opt/conda/lib/python3.10/site-packages (2.31.0)\nCollecting xformers==0.0.20\n  Downloading xformers-0.0.20-cp310-cp310-manylinux2014_x86_64.whl (109.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.1/109.1 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting triton==2.0.0\n  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests==2.31.0) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests==2.31.0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests==2.31.0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests==2.31.0) (2023.5.7)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xformers==0.0.20) (1.23.5)\nCollecting pyre-extensions==0.0.29 (from xformers==0.0.20)\n  Downloading pyre_extensions-0.0.29-py3-none-any.whl (12 kB)\nCollecting torch==2.0.1 (from xformers==0.0.20)\n  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/619.9 MB\u001b[0m \u001b[31m172.6 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"### \n### Configuration and downloading default models - Required","metadata":{"execution":{"iopub.status.busy":"2024-04-08T07:19:08.106554Z","iopub.execute_input":"2024-04-08T07:19:08.106959Z","iopub.status.idle":"2024-04-08T07:19:23.905268Z","shell.execute_reply.started":"2024-04-08T07:19:08.106924Z","shell.execute_reply":"2024-04-08T07:19:23.904291Z"}}},{"cell_type":"code","source":"!mkdir /kaggle/temp/\n!mkdir /kaggle/temp/invokeai\n!mkdir /kaggle/temp/invokeai/configs\n\n#@markdown Download only the default model in initial configuration.\n#@markdown Checking this prevents running out of space in Colab.\n\ndefaultOnly = True #@param {type:\"boolean\"}\nskipWeights = True #@param {type:\"boolean\"}\nskipSupportModels = False #@param {type:\"boolean\"}\nnoFullPrecision = True\n\n#@markdown This step usually takes about 2 minutes with only the default model and no weights.\n\n#@markdown You can ignore \"File exists\" warnings in the output.\n\ncmd = 'invokeai-configure --root_dir /kaggle/temp/invokeai --yes'\n\nif defaultOnly:\n  cmd += ' --default_only'\n\nif skipWeights:\n  cmd += ' --skip-sd-weights'\n\nif skipSupportModels:\n  cmd += ' --skip-support-models'\n\nsubprocess.run(cmd, shell=True, env=env)\n\nimport fileinput\nimport os\ndef find(name, path):\n    for root, dirs, files in os.walk(path):\n        if name in files:\n            return os.path.join(root, name)\n\nif noFullPrecision:\n  model_install_file = find('model_install_backend.py', '/opt/conda/lib/')\n  print('modifying file ' + str(model_install_file))\n  for line in fileinput.input(model_install_file, inplace=True):\n    if ('precision = torch_dtype(choose_torch_device())' in line):\n       line = line.replace('torch_dtype(choose_torch_device())', 'torch.float16')\n    print(line, end='')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### \n### Add the Dreamshaper SDXL model (optional)","metadata":{"execution":{"iopub.status.busy":"2024-04-08T07:21:33.763307Z","iopub.execute_input":"2024-04-08T07:21:33.763647Z","iopub.status.idle":"2024-04-08T07:21:34.715565Z","shell.execute_reply.started":"2024-04-08T07:21:33.763621Z","shell.execute_reply":"2024-04-08T07:21:34.714436Z"}}},{"cell_type":"code","source":"import os.path\nfrom os import path\n\n# Install the SDXL base model\ndef installSdxl(env):\n  installCmd = 'invokeai-model-install --add \"Lykon/dreamshaper-xl-1-0\" --root_dir /kaggle/temp/invokeai'\n  subprocess.run(installCmd, shell=True, env=env)\n  \nalreadyInstalled = True\nsdxlBaseSubfolderName = ''\nmodelsPath = '/kaggle/working/stablemodels/'\nsdxlBaseSubfolderName = '/dreamshaper-xl-1-0'\nworkSdxlMainFolder = modelsPath + 'sdxl/main'\nif not path.exists(workSdxlMainFolder):\n    os.makedirs(workSdxlMainFolder, exist_ok=True)\n    alreadyInstalled = False\n\ntempModelsSdxlFolder = '/kaggle/temp/invokeai/models/sdxl/'\ntempSdxlMainFolder = tempModelsSdxlFolder + 'main'\n\nsubprocess.run('rm -rf ' + tempModelsSdxlFolder, shell=True, env=env)\nif path.exists(tempModelsSdxlFolder):\n    subprocess.run('rmdir ' + tempModelsSdxlFolder, shell=True, env=env)\n\nif not alreadyInstalled:\n    if not path.exists(tempModelsSdxlFolder):\n      os.makedirs(tempModelsSdxlFolder, exist_ok=True)\n    subprocess.run('ln -s '+workSdxlMainFolder+' '+tempModelsSdxlFolder, shell=True, env=env)\n    installSdxl(env)\nelse:\n    if not path.exists(tempSdxlMainFolder):\n      os.makedirs(tempSdxlMainFolder, exist_ok=True)\n    subprocess.run('ln -s '+workSdxlMainFolder + sdxlBaseSubfolderName+' '+ tempSdxlMainFolder, shell=True, env=env)\n    updateModelsYaml = True\n    with open('/kaggle/temp/invokeai/configs/models.yaml') as f:\n      if 'dreamshaper-xl-1-0' in f.read():\n        updateModelsYaml = False\n    if updateModelsYaml:\n      with open('/kaggle/temp/invokeai/configs/models.yaml', 'a') as file:\n        lines = [\n          'sdxl/main/dreamshaper-xl-1-0:\\n',\n          '  path: sdxl/main/dreamshaper-xl-1-0\\n',\n          '  description: Dreamshaper XL (12 GB)\\n',\n          '  variant: normal\\n',\n          '  format: diffusers\\n'\n        ]\n        file.writelines(lines)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### \n### Save images to the working folder (optional)\nIf file persistance is enabled, images and the database will be saved for future sessions","metadata":{}},{"cell_type":"code","source":"import os.path\nfrom os import path\n\n# Linking output images to working folder\noutputDrivePath = '/kaggle/working/images/invoke-outputs' #@param {type:\"string\"}\n# Full path to the output folder on Google Drive\n\nsaveDatabase = True #@param {type:\"boolean\"}\n\nif not outputDrivePath.endswith('/'):\n  outputDrivePath = outputDrivePath + '/'\nimagesDrivePath = outputDrivePath + 'images'\ndatabaseDrivePath = outputDrivePath + 'databases'\nif not path.exists(imagesDrivePath):\n  os.makedirs(imagesDrivePath, exist_ok=True)\n\n\noutputsLocalPath = '/kaggle/temp/invokeai/outputs'\nimagesLocalPath = '/kaggle/temp/invokeai/outputs/images'\n\nif not path.exists(outputsLocalPath):\n  os.makedirs(outputsLocalPath, exist_ok=True)\n\nimport datetime\n\nif path.exists(imagesLocalPath):\n    cmd = f'mv {imagesLocalPath} {imagesLocalPath}-backup{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n    subprocess.run(cmd, shell=True, env=env)\n\ncmd = f'ln -s {imagesDrivePath} {outputsLocalPath}'\nsubprocess.run(cmd, shell=True, env=env)\n\n# Linking the database\nif saveDatabase:\n  if not path.exists(databaseDrivePath):\n    os.makedirs(databaseDrivePath, exist_ok=True)\n\n  databaseLocalPath = '/kaggle/temp/invokeai/databases'\n\n  cmd = f'mv {databaseLocalPath} {databaseLocalPath}-backup{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n  subprocess.run(cmd, shell=True, env=env)\n\n  cmd = f'ln -s {databaseDrivePath} /kaggle/temp/invokeai'\n  subprocess.run(cmd, shell=True, env=env)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### \n### Start the WebUI","metadata":{}},{"cell_type":"markdown","source":"**Option 1: Starting the Web UI with ngrok**  \n* Make sure to put your ngrok token in the Ngrok_token variable. The token can be obtained from https://ngrok.com\n* If you have a static domain, put your ngrok domain in the Ngrok_domain variable.\n* Wait for the line that says \"Uvicorn running on http://127.0.0.1:9090 (Press CTRL+C to quit)\" \n* Visit your ngrok URL (either your static domain, or the ngrok url displayed in the output)","metadata":{}},{"cell_type":"code","source":"# Option 1: Starting the Web UI with ngrok\n\nNgrok_token = \"\" #@param {type:\"string\"}\n# Put your ngrok token here (obtainable from https://ngrok.com)\n\nNgrok_domain = \"\" # optional, leave empty if you don't have a domain\n\n# Only works with InvokeAI 3.0.2 and later\n\n!pip install pyngrok\n\nfrom pyngrok import ngrok, conf\nimport fileinput\nimport sys\n\nif Ngrok_token!=\"\":\n  ngrok.kill()\n  srv=ngrok.connect(9090 , pyngrok_config=conf.PyngrokConfig(auth_token=Ngrok_token),\n                    bind_tls=True, domain=Ngrok_domain).public_url\n  print(srv)\n  get_ipython().system(\"invokeai-web  --root /kaggle/temp/invokeai/\")\nelse:\n  print('An ngrok token is required. You can get one on https://ngrok.com and paste it into the ngrok_token field.')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***   \n**Option 2: Starting the Web UI with RemoteMoe**  \n* Wait for the line that says \"Uvicorn running on http://127.0.0.1:9090 (Press CTRL+C to quit)\"   \n* Click the link that ends with .remote.moe","metadata":{}},{"cell_type":"code","source":"#Option 2: Starting the Web UI with RemoteMoe\n\n# Wait for the line that says \"Uvicorn running on http://127.0.0.1:9090 (Press CTRL+C to quit)\" \n# and click on the link that ends with .remote.moe\n\n!mkdir  ~/.ssh/\n!touch  ~/.ssh/known_hosts\n!ssh-keyscan -t rsa remote.moe >> ~/.ssh/known_hosts\n!rm /root/.ssh/id_rsa\n!ssh-keygen -t rsa -b 4096 -f /root/.ssh/id_rsa -q -N \"\"\n!invokeai-web --root /kaggle/temp/invokeai/ & ssh -R 80:127.0.0.1:9090 -o StrictHostKeyChecking=no -i /root/.ssh/id_rsa remote.moe ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***   \n**Option 3: Starting the Web UI with Localtunnel**  \n* Copy the IP address shown in the output above the line \"your url is: https://some-random-words.loca.lt\"  \n* Wait for the line that says \"Uvicorn running on http://127.0.0.1:9090 (Press CTRL+C to quit)\"   \n* Click the localtunnel url and paste the IP you copied earlier to the \"Endpoint IP\" text field\n","metadata":{}},{"cell_type":"code","source":"# Option 3: Starting the Web UI with Localtunnel\n# Warning: Localtunnel has been down recently. If the .loca.lt link doesn't show up in the output\n# please use one of the other two options\n\n%cd /kaggle/temp/invokeai/\n!npm install -g localtunnel\n\n#@markdown Copy the IP address shown in the output above the line\n#@markdown \"your url is: https://some-random-words.loca.lt\"\n!wget -q -O - ipv4.icanhazip.com\n\n#@markdown Wait for the line that says \"Uvicorn running on http://127.0.0.1:9090 (Press CTRL+C to quit)\"\n\n#@markdown Click the localtunnel url and paste the IP you copied earlier to the \"Endpoint IP\" text field\n!lt --port 9090 --local_https False & invokeai-web  --root /kaggle/temp/invokeai/ --ignore_missing_core_models \n\n#@markdown If the UI shows a red dot that says 'disconnected' when hovered in the upper\n#@markdown right corner and the Invoke button is disabled, change 'https' to 'http'\n#@markdown in the browser's address bar and press enter.\n#@markdown When the page reloads, the UI should work properly.\n","metadata":{"execution":{"iopub.status.busy":"2024-04-08T07:52:02.680507Z","iopub.execute_input":"2024-04-08T07:52:02.681408Z","iopub.status.idle":"2024-04-08T07:59:14.051161Z","shell.execute_reply.started":"2024-04-08T07:52:02.68137Z","shell.execute_reply":"2024-04-08T07:59:14.049578Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"/kaggle/temp/invokeai\n\u001b[K\u001b[?25hm#################\u001b[0m\u001b[100;90m⠂\u001b[0m) ⠧ reify:yargs-parser: \u001b[32;40mhttp\u001b[0m \u001b[35mfetch\u001b[0m GET 200 https://registry.\u001b[0m\u001b[K\nadded 22 packages in 982ms\n\n3 packages are looking for funding\n  run `npm fund` for details\n\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m \n\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m New \u001b[31mmajor\u001b[39m version of npm available! \u001b[31m9.5.0\u001b[39m -> \u001b[32m10.5.1\u001b[39m\n\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m Changelog: \u001b[36mhttps://github.com/npm/cli/releases/tag/v10.5.1\u001b[39m\n\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m Run \u001b[32mnpm install -g npm@10.5.1\u001b[39m to update!\n\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m \n\u001b[0m34.127.102.97\nyour url is: https://large-guests-hang.loca.lt\n/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n>> patchmatch.patch_match: INFO - Compiling and loading c extensions from \"/opt/conda/lib/python3.10/site-packages/patchmatch\".\n>> patchmatch.patch_match: WARNING - patchmatch failed to load or compile.\n>> patchmatch.patch_match: WARNING - Refer to https://github.com/invoke-ai/InvokeAI/blob/main/docs/installation/INSTALL_PATCHMATCH.md for installation instructions.\n\u001b[38;20m[2024-04-08 07:52:22,964]::[InvokeAI]::INFO --> Patchmatch not loaded (nonfatal)\u001b[0m\n/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n  warnings.warn(\n\u001b[38;20m[2024-04-08 07:52:28,719]::[uvicorn.error]::INFO --> Started server process [553]\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:28,719]::[uvicorn.error]::INFO --> Waiting for application startup.\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:28,719]::[InvokeAI]::INFO --> InvokeAI version 3.6.0\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:28,719]::[InvokeAI]::INFO --> Root directory = /kaggle/temp/invokeai\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:28,720]::[InvokeAI]::INFO --> Initializing database at /kaggle/working/images/invoke-outputs/databases/invokeai.db\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:28,732]::[InvokeAI]::INFO --> GPU device = cuda Tesla P100-PCIE-16GB\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:28,736]::[InvokeAI]::INFO --> Scanning /kaggle/temp/invokeai/models for new models\u001b[0m\n\u001b[33;20m[2024-04-08 07:52:28,744]::[InvokeAI]::WARNING --> Error loading model sdxl/main/dreamshaper-xl-1-0. [Errno 2] No such file or directory: 'sdxl/main/dreamshaper-xl-1-0'\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:29,143]::[InvokeAI]::INFO --> Scanned 9 files and directories, imported 0 models\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:29,143]::[InvokeAI]::INFO --> Model manager service initialized\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:29,145]::[ModelInstallService]::INFO --> Checking for models that have been moved or deleted from disk\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:29,146]::[ModelInstallService]::INFO --> stable-diffusion-xl-base-1-0: path sdxl/main/stable-diffusion-xl-base-1-0 no longer exists. Unregistering\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:29,157]::[ModelInstallService]::INFO --> Scanning /kaggle/temp/invokeai/models for new and orphaned models\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:29,161]::[ModelInstallService]::INFO --> 0 new models registered; 1 unregistered\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:29,162]::[ModelInstallService]::INFO --> Scanning autoimport directory for new models\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:29,163]::[ModelInstallService]::INFO --> 0 new models registered\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:29,163]::[ModelInstallService]::INFO --> Model installer (re)initialized\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:29,184]::[InvokeAI]::INFO --> Pruned 9 finished queue items\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:29,285]::[InvokeAI]::INFO --> Cleaned database (freed 0.05MB)\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:29,285]::[uvicorn.error]::INFO --> Application startup complete.\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:29,285]::[uvicorn.error]::INFO --> Uvicorn running on http://127.0.0.1:9090 (Press CTRL+C to quit)\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:29,451]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET / HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:30,689]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /index-58ecvHlx.js HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:31,430]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /en.json HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:31,437]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /ThemeLocaleProvider-Ugl3I94y.css HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:31,438]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /ThemeLocaleProvider-2DzbI6NZ.js HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:31,650]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /images/invoke-favicon.svg HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:34,461]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /chunk-VMD3UMGK-uvnz6tkL.js HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:34,682]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /App-yOqAlINK.css HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:34,687]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /App-ikQCYSNj.js HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:35,421]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /socket.io/?EIO=4&transport=polling&t=OwyiTGB HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:35,510]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/queue/default/status HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:35,511]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/app/version HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:35,513]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/models/?base_models=sd-1&base_models=sd-2&base_models=sdxl&model_type=main HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:35,516]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/models/?model_type=t2i_adapter HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:35,517]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/models/?model_type=lora HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:35,518]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/models/?model_type=controlnet HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:35,520]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/models/?model_type=ip_adapter HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:35,521]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/models/?model_type=vae HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:35,599]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/boards/?all=true HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:35,696]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/?board_id=none&categories=general&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:35,702]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/?board_id=none&categories=general&is_intermediate=false&limit=100&offset=0 HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:36,409]::[InvokeAI]::INFO --> NSFW checker initialized\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:36,410]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/app/config HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:36,412]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/intermediates HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:36,415]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /inter-latin-wght-normal-YFatk6uG.woff2 HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:36,587]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"POST /socket.io/?EIO=4&transport=polling&t=OwyiTJP&sid=bDRb5P-lPH6V8J1NAAAA HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:36,589]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /socket.io/?EIO=4&transport=polling&t=OwyiTJR&sid=bDRb5P-lPH6V8J1NAAAA HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:36,707]::[uvicorn.error]::INFO --> ('188.252.197.19', 0) - \"WebSocket /socket.io/?EIO=4&transport=websocket&sid=bDRb5P-lPH6V8J1NAAAA\" [accepted]\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:36,708]::[uvicorn.error]::INFO --> connection open\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:36,726]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/ec4985b6-c763-4fe8-96eb-72e9056fc16e.png/metadata HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:36,728]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/?board_id=none&categories=control&categories=mask&categories=user&categories=other&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:36,731]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/ec4985b6-c763-4fe8-96eb-72e9056fc16e.png/thumbnail HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:38,188]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /openapi.json HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:38,191]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"POST /socket.io/?EIO=4&transport=polling&t=OwyiTbt&sid=bDRb5P-lPH6V8J1NAAAA HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:38,191]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /socket.io/?EIO=4&transport=polling&t=OwyiTbp&sid=bDRb5P-lPH6V8J1NAAAA HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:38,385]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/f6ad0aac-15cc-44d1-b48e-862288476161.png/thumbnail HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:38,850]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/91d0448b-7b65-44ef-ba3b-5f8662fc674f.png/thumbnail HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:39,450]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/e3ce3f54-4f62-442e-a8db-657f4c2112c7.png/thumbnail HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:39,804]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/54029214-d712-4e17-a813-0be03650dbfb.png/thumbnail HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:39,960]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/12eece82-704b-47c2-a12c-3e3f467897a1.png/thumbnail HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:39,996]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/8212d40e-ea33-4d34-8d29-d51757b3bbf0.png/thumbnail HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:40,187]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/8356e709-5ec7-422e-b4a1-32617c4daed8.png/thumbnail HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:40,369]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/81cadb31-04f3-4bde-8719-556c64d33efa.png/thumbnail HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:40,446]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/491cf189-7f78-45ab-ba24-1dc30fab93fb.png/thumbnail HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:40,552]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/98bafdc7-1415-4246-91fc-657a76c81d19.png/thumbnail HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:40,626]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/8e095105-9a4f-4fe3-bc4f-ed44c5ea7760.png/thumbnail HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:40,733]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/4651c9cc-7d15-482a-b45a-5e72a227561b.png/thumbnail HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:40,861]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/ab616e70-74a4-4007-b483-bc5c8becdf5f.png/thumbnail HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:41,463]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/c810b7a5-1b15-4b22-97de-5da611258f1b.png/thumbnail HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:42,807]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/8efeb3b1-20eb-4b1c-bf78-71c70303645b.png/thumbnail HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:42,809]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/e7d6a895-7ad1-4638-94d5-edf6579fa88a.png/thumbnail HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:43,160]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/2d299b19-d766-4e00-a47b-cdb228425ece.png/thumbnail HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:43,161]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/de2e5703-6c30-46d6-82ea-72ac07602781.png/thumbnail HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:43,344]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/52e490af-ae89-479e-a371-f7e9568d1f15.png/thumbnail HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:43,346]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/601d4f0e-adcb-4701-90cd-133cafe9b2dc.png/thumbnail HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:43,526]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/7e864969-e11b-4aff-8887-92ced591237b.png/thumbnail HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:43,706]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/3c6e9fea-a111-4bee-8290-f3be12ccd2e5.png/thumbnail HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:43,886]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/2cc92903-0df2-4ccc-a601-9fdf30e6842e.png/thumbnail HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:44,066]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/3040631b-956a-442b-b991-3e51ddbaa769.png/thumbnail HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:44,152]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/ed11df7f-555e-4ffa-ab30-5bc7f2abbb63.png/thumbnail HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:44,920]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/ec4985b6-c763-4fe8-96eb-72e9056fc16e.png/full HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:52:48,350]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/models/?base_models=sd-1&base_models=sd-2&base_models=sdxl&base_models=sdxl-refiner&model_type=main HTTP/1.1\" 200\u001b[0m\nmodel_index.json: 100%|████████████████████████| 579/579 [00:00<00:00, 2.82MB/s]\nunet/diffusion_pytorch_model.safetensors not found\nFetching 13 files:   0%|                                 | 0/13 [00:00<?, ?it/s]\ntokenizer/tokenizer_config.json: 100%|█████████| 737/737 [00:00<00:00, 3.66MB/s]\u001b[A\n\ntext_encoder/config.json: 100%|████████████████| 612/612 [00:00<00:00, 3.76MB/s]\u001b[A\n\ntokenizer/merges.txt:   0%|                          | 0.00/525k [00:00<?, ?B/s]\u001b[A\n\ntokenizer/vocab.json:   0%|                         | 0.00/1.06M [00:00<?, ?B/s]\u001b[A\u001b[A\n\n\ntokenizer/special_tokens_map.json: 100%|███████| 472/472 [00:00<00:00, 2.32MB/s]\u001b[A\u001b[A\u001b[A\n\n\n\nscheduler/scheduler_config.json: 100%|█████████| 528/528 [00:00<00:00, 3.04MB/s]\u001b[A\u001b[A\u001b[A\n\n\n\npytorch_model.bin:   0%|                             | 0.00/492M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n\n\n\nunet/config.json: 100%|████████████████████| 1.58k/1.58k [00:00<00:00, 10.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n\ntokenizer/merges.txt: 100%|██████████████████| 525k/525k [00:00<00:00, 2.86MB/s]\u001b[A\n\n\ntokenizer/vocab.json: 100%|████████████████| 1.06M/1.06M [00:00<00:00, 7.29MB/s]\u001b[A\u001b[A\n\n\n\npytorch_model.bin:   4%|▉                    | 21.0M/492M [00:00<00:02, 180MB/s]\u001b[A\u001b[A\u001b[A\n(…)ature_extractor/preprocessor_config.json: 100%|█| 520/520 [00:00<00:00, 1.85M\u001b[A\nFetching 13 files:   8%|█▉                       | 1/13 [00:00<00:06,  1.94it/s]\ndiffusion_pytorch_model.bin:   0%|                   | 0.00/335M [00:00<?, ?B/s]\u001b[A\n\nvae/config.json: 100%|█████████████████████████| 577/577 [00:00<00:00, 2.70MB/s]\u001b[A\u001b[A\n\n\n\npytorch_model.bin:  11%|██▏                  | 52.4M/492M [00:00<00:01, 243MB/s]\u001b[A\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:   0%|                  | 0.00/3.44G [00:00<?, ?B/s]\u001b[A\u001b[A\ndiffusion_pytorch_model.bin:   6%|▋          | 21.0M/335M [00:00<00:01, 172MB/s]\u001b[A\n\n\npytorch_model.bin:  17%|███▌                 | 83.9M/492M [00:00<00:01, 248MB/s]\u001b[A\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:   1%|          | 21.0M/3.44G [00:00<00:19, 178MB/s]\u001b[A\u001b[A\ndiffusion_pytorch_model.bin:  16%|█▋         | 52.4M/335M [00:00<00:01, 229MB/s]\u001b[A\n\n\npytorch_model.bin:  23%|█████▏                | 115M/492M [00:00<00:01, 251MB/s]\u001b[A\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:   2%|▏         | 52.4M/3.44G [00:00<00:14, 229MB/s]\u001b[A\u001b[A\ndiffusion_pytorch_model.bin:  25%|██▊        | 83.9M/335M [00:00<00:01, 229MB/s]\u001b[A\n\n\npytorch_model.bin:  30%|██████▌               | 147M/492M [00:00<00:01, 264MB/s]\u001b[A\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:   2%|▏         | 83.9M/3.44G [00:00<00:14, 234MB/s]\u001b[A\u001b[A\ndiffusion_pytorch_model.bin:  34%|████▏       | 115M/335M [00:00<00:00, 230MB/s]\u001b[A\n\n\npytorch_model.bin:  36%|███████▉              | 178M/492M [00:00<00:01, 266MB/s]\u001b[A\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:   3%|▎          | 115M/3.44G [00:00<00:14, 232MB/s]\u001b[A\u001b[A\ndiffusion_pytorch_model.bin:  44%|█████▎      | 147M/335M [00:00<00:00, 233MB/s]\u001b[A\n\n\npytorch_model.bin:  43%|█████████▎            | 210M/492M [00:00<00:01, 258MB/s]\u001b[A\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:   4%|▍          | 147M/3.44G [00:00<00:13, 238MB/s]\u001b[A\u001b[A\ndiffusion_pytorch_model.bin:  53%|██████▍     | 178M/335M [00:00<00:00, 229MB/s]\u001b[A\n\n\npytorch_model.bin:  49%|██████████▊           | 241M/492M [00:00<00:00, 266MB/s]\u001b[A\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:   5%|▌          | 178M/3.44G [00:00<00:13, 247MB/s]\u001b[A\u001b[A\ndiffusion_pytorch_model.bin:  63%|███████▌    | 210M/335M [00:00<00:00, 226MB/s]\u001b[A\n\n\npytorch_model.bin:  55%|████████████▏         | 273M/492M [00:01<00:00, 251MB/s]\u001b[A\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:   6%|▋          | 210M/3.44G [00:00<00:13, 243MB/s]\u001b[A\u001b[A\ndiffusion_pytorch_model.bin:  72%|████████▋   | 241M/335M [00:01<00:00, 225MB/s]\u001b[A\n\n\npytorch_model.bin:  62%|█████████████▌        | 304M/492M [00:01<00:00, 235MB/s]\u001b[A\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:   7%|▊          | 241M/3.44G [00:01<00:13, 238MB/s]\u001b[A\u001b[A\ndiffusion_pytorch_model.bin:  81%|█████████▊  | 273M/335M [00:01<00:00, 232MB/s]\u001b[A\n\n\npytorch_model.bin:  68%|██████████████▉       | 336M/492M [00:01<00:00, 233MB/s]\u001b[A\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:   8%|▊          | 273M/3.44G [00:01<00:13, 234MB/s]\u001b[A\u001b[A\ndiffusion_pytorch_model.bin:  91%|██████████▉ | 304M/335M [00:01<00:00, 237MB/s]\u001b[A\n\n\npytorch_model.bin:  75%|████████████████▍     | 367M/492M [00:01<00:00, 237MB/s]\u001b[A\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:   9%|▉          | 304M/3.44G [00:01<00:13, 234MB/s]\u001b[A\u001b[A\ndiffusion_pytorch_model.bin: 100%|████████████| 335M/335M [00:01<00:00, 229MB/s]\u001b[A\n\n\n\npytorch_model.bin:  81%|█████████████████▊    | 398M/492M [00:01<00:00, 237MB/s]\u001b[A\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  10%|█          | 336M/3.44G [00:01<00:12, 247MB/s]\u001b[A\u001b[A\n\n\npytorch_model.bin:  87%|███████████████████▏  | 430M/492M [00:01<00:00, 253MB/s]\u001b[A\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  11%|█▏         | 367M/3.44G [00:01<00:13, 230MB/s]\u001b[A\u001b[A\n\n\npytorch_model.bin: 100%|██████████████████████| 492M/492M [00:01<00:00, 253MB/s]\u001b[A\u001b[A\u001b[A\nFetching 13 files:  38%|█████████▌               | 5/13 [00:02<00:03,  2.15it/s]\n\ndiffusion_pytorch_model.bin:  12%|█▎         | 398M/3.44G [00:01<00:17, 173MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  13%|█▍         | 440M/3.44G [00:01<00:14, 210MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  14%|█▌         | 482M/3.44G [00:02<00:12, 241MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  15%|█▋         | 524M/3.44G [00:02<00:11, 263MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  16%|█▊         | 566M/3.44G [00:02<00:10, 283MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  18%|█▉         | 608M/3.44G [00:02<00:09, 297MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  19%|██         | 650M/3.44G [00:02<00:09, 307MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  20%|██▏        | 692M/3.44G [00:02<00:08, 316MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  21%|██▎        | 734M/3.44G [00:02<00:08, 319MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  23%|██▍        | 776M/3.44G [00:02<00:08, 322MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  24%|██▌        | 818M/3.44G [00:03<00:08, 319MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  25%|██▊        | 860M/3.44G [00:03<00:08, 322MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  26%|██▉        | 902M/3.44G [00:03<00:07, 325MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  27%|███        | 944M/3.44G [00:03<00:07, 328MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  29%|███▏       | 986M/3.44G [00:03<00:07, 327MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  30%|██▉       | 1.03G/3.44G [00:03<00:07, 323MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  31%|███       | 1.07G/3.44G [00:03<00:07, 322MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  32%|███▏      | 1.11G/3.44G [00:04<00:07, 321MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  34%|███▎      | 1.15G/3.44G [00:04<00:07, 323MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  35%|███▍      | 1.20G/3.44G [00:04<00:06, 325MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  36%|███▌      | 1.24G/3.44G [00:04<00:06, 326MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  37%|███▋      | 1.28G/3.44G [00:04<00:06, 329MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  38%|███▊      | 1.32G/3.44G [00:04<00:06, 330MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  40%|███▉      | 1.36G/3.44G [00:04<00:06, 330MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  41%|████      | 1.41G/3.44G [00:04<00:06, 330MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  42%|████▏     | 1.45G/3.44G [00:05<00:06, 326MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  43%|████▎     | 1.49G/3.44G [00:05<00:05, 326MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  45%|████▍     | 1.53G/3.44G [00:05<00:05, 324MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  46%|████▌     | 1.57G/3.44G [00:05<00:05, 322MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  47%|████▋     | 1.61G/3.44G [00:05<00:05, 324MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  48%|████▊     | 1.66G/3.44G [00:05<00:05, 324MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  49%|████▉     | 1.70G/3.44G [00:05<00:05, 328MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  51%|█████     | 1.74G/3.44G [00:05<00:05, 329MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  52%|█████▏    | 1.78G/3.44G [00:06<00:05, 331MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  53%|█████▎    | 1.82G/3.44G [00:06<00:04, 330MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  54%|█████▍    | 1.87G/3.44G [00:06<00:04, 331MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  56%|█████▌    | 1.91G/3.44G [00:06<00:04, 333MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  57%|█████▋    | 1.95G/3.44G [00:06<00:04, 333MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  58%|█████▊    | 1.99G/3.44G [00:06<00:04, 331MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  59%|█████▉    | 2.03G/3.44G [00:06<00:04, 331MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  60%|██████    | 2.08G/3.44G [00:06<00:04, 316MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  62%|██████▏   | 2.12G/3.44G [00:07<00:04, 316MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  63%|██████▎   | 2.16G/3.44G [00:07<00:04, 310MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  64%|██████▎   | 2.19G/3.44G [00:07<00:04, 310MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  65%|██████▍   | 2.22G/3.44G [00:07<00:03, 305MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  66%|██████▌   | 2.25G/3.44G [00:07<00:03, 307MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  67%|██████▋   | 2.30G/3.44G [00:07<00:03, 310MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  68%|██████▊   | 2.33G/3.44G [00:07<00:03, 307MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  69%|██████▊   | 2.36G/3.44G [00:07<00:03, 305MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  70%|██████▉   | 2.39G/3.44G [00:08<00:03, 303MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  70%|███████   | 2.42G/3.44G [00:08<00:03, 302MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  71%|███████▏  | 2.45G/3.44G [00:08<00:03, 303MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  72%|███████▏  | 2.49G/3.44G [00:08<00:03, 303MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  73%|███████▎  | 2.52G/3.44G [00:08<00:03, 305MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  74%|███████▍  | 2.56G/3.44G [00:08<00:02, 309MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  75%|███████▌  | 2.59G/3.44G [00:08<00:02, 309MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  76%|███████▌  | 2.62G/3.44G [00:08<00:02, 306MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  77%|███████▋  | 2.65G/3.44G [00:08<00:02, 306MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  78%|███████▊  | 2.68G/3.44G [00:08<00:02, 297MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  79%|███████▉  | 2.73G/3.44G [00:09<00:02, 306MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  81%|████████  | 2.77G/3.44G [00:09<00:02, 310MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  81%|████████▏ | 2.80G/3.44G [00:09<00:02, 311MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  83%|████████▎ | 2.84G/3.44G [00:09<00:01, 313MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  84%|████████▎ | 2.87G/3.44G [00:09<00:01, 310MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  84%|████████▍ | 2.90G/3.44G [00:09<00:01, 308MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  85%|████████▌ | 2.94G/3.44G [00:09<00:01, 309MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  86%|████████▋ | 2.97G/3.44G [00:09<00:01, 309MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  87%|████████▋ | 3.00G/3.44G [00:09<00:01, 310MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  88%|████████▊ | 3.03G/3.44G [00:10<00:01, 308MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  89%|████████▉ | 3.06G/3.44G [00:10<00:01, 303MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  90%|████████▉ | 3.09G/3.44G [00:10<00:01, 298MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  91%|█████████ | 3.12G/3.44G [00:10<00:01, 290MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  92%|█████████▏| 3.16G/3.44G [00:10<00:01, 282MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  93%|█████████▎| 3.19G/3.44G [00:10<00:00, 269MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  94%|█████████▎| 3.22G/3.44G [00:10<00:00, 272MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  95%|█████████▍| 3.25G/3.44G [00:10<00:00, 275MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  95%|█████████▌| 3.28G/3.44G [00:11<00:00, 281MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  97%|█████████▋| 3.32G/3.44G [00:11<00:00, 296MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  98%|█████████▊| 3.37G/3.44G [00:11<00:00, 306MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin:  99%|█████████▉| 3.40G/3.44G [00:11<00:00, 297MB/s]\u001b[A\u001b[A\n\ndiffusion_pytorch_model.bin: 100%|██████████| 3.44G/3.44G [00:11<00:00, 299MB/s]\u001b[A\u001b[A\nFetching 13 files: 100%|████████████████████████| 13/13 [00:12<00:00,  1.07it/s]\nKeyword arguments {'subfolder': None} are not expected by StableDiffusionPipeline and will be ignored.\nLoading pipeline components...: 100%|█████████████| 6/6 [00:05<00:00,  1.15it/s]\nYou have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n\u001b[38;20m[2024-04-08 07:53:31,363]::[InvokeAI]::INFO --> Successfully imported Lykon/DreamShaper, got name='DreamShaper' model_type=<ModelType.Main: 'main'> base_model=<BaseModelType.StableDiffusion1: 'sd-1'> config=DiffusersConfig(path='sd-1/main/DreamShaper', description='sd-1 main model DreamShaper', model_format=<StableDiffusion1ModelFormat.Diffusers: 'diffusers'>, error=None, vae=None, variant='normal')\u001b[0m\n\u001b[38;20m[2024-04-08 07:53:31,365]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"POST /api/v1/models/import HTTP/1.1\" 201\u001b[0m\n\u001b[38;20m[2024-04-08 07:53:31,369]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /socket.io/?EIO=4&transport=polling&t=OwyifAF HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:53:31,370]::[uvicorn.error]::INFO --> connection closed\u001b[0m\n\u001b[38;20m[2024-04-08 07:53:31,575]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/models/?model_type=t2i_adapter HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:53:31,577]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/models/?model_type=controlnet HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:53:31,578]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/models/?model_type=lora HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:53:31,579]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/models/?model_type=ip_adapter HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:53:31,590]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"POST /socket.io/?EIO=4&transport=polling&t=Owyigzo&sid=8z2fXD8u9P_EVGWrAAAC HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:53:31,591]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /socket.io/?EIO=4&transport=polling&t=Owyigzq&sid=8z2fXD8u9P_EVGWrAAAC HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:53:31,793]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"POST /socket.io/?EIO=4&transport=polling&t=Owyih0y&sid=8z2fXD8u9P_EVGWrAAAC HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:53:31,795]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/queue/default/status HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:53:31,858]::[uvicorn.error]::INFO --> ('188.252.197.19', 0) - \"WebSocket /socket.io/?EIO=4&transport=websocket&sid=8z2fXD8u9P_EVGWrAAAC\" [accepted]\u001b[0m\n\u001b[38;20m[2024-04-08 07:53:31,858]::[uvicorn.error]::INFO --> connection open\u001b[0m\n\u001b[38;20m[2024-04-08 07:53:32,053]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /socket.io/?EIO=4&transport=polling&t=Owyih0x&sid=8z2fXD8u9P_EVGWrAAAC HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:54:41,651]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/models/?base_models=sd-1&base_models=sd-2&base_models=sdxl&model_type=main HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:54:41,653]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/models/?model_type=vae HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:54:41,655]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/?board_id=none&categories=control&categories=mask&categories=user&categories=other&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:54:41,656]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/?board_id=none&categories=general&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:54:51,486]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"POST /api/v1/queue/default/enqueue_batch HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:54:51,692]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/queue/default/status HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:54:51,696]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/queue/default/list HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:54:51,697]::[InvokeAI]::INFO --> Loading model /kaggle/temp/invokeai/models/sd-1/main/DreamShaper, type sd-1:main:tokenizer\u001b[0m\n\u001b[38;20m[2024-04-08 07:54:51,778]::[InvokeAI]::INFO --> Loading model /kaggle/temp/invokeai/models/sd-1/main/DreamShaper, type sd-1:main:text_encoder\u001b[0m\n\u001b[38;20m[2024-04-08 07:54:53,226]::[InvokeAI]::INFO --> Loading model /kaggle/temp/invokeai/models/sd-1/main/DreamShaper, type sd-1:main:unet\u001b[0m\n\u001b[38;20m[2024-04-08 07:54:54,017]::[InvokeAI]::INFO --> Loading model /kaggle/temp/invokeai/models/sd-1/main/DreamShaper, type sd-1:main:scheduler\u001b[0m\n100%|███████████████████████████████████████████| 31/31 [00:09<00:00,  3.33it/s]\n\u001b[38;20m[2024-04-08 07:55:03,709]::[InvokeAI]::INFO --> Loading model /kaggle/temp/invokeai/models/sd-1/main/DreamShaper, type sd-1:main:vae\u001b[0m\n\u001b[38;20m[2024-04-08 07:55:06,231]::[InvokeAI]::INFO --> Graph stats: ef0ba952-9d79-4810-9579-921c19da9e7b\u001b[0m\n\u001b[38;20m[2024-04-08 07:55:06,232]::[InvokeAI]::INFO -->                           Node   Calls  Seconds  VRAM Used\u001b[0m\n\u001b[38;20m[2024-04-08 07:55:06,232]::[InvokeAI]::INFO -->              main_model_loader     1     0.014s     0.000G\u001b[0m\n\u001b[38;20m[2024-04-08 07:55:06,232]::[InvokeAI]::INFO -->                      clip_skip     1     0.010s     0.000G\u001b[0m\n\u001b[38;20m[2024-04-08 07:55:06,232]::[InvokeAI]::INFO -->                         compel     2     1.450s     0.246G\u001b[0m\n\u001b[38;20m[2024-04-08 07:55:06,232]::[InvokeAI]::INFO -->                          noise     1     0.016s     0.244G\u001b[0m\n\u001b[38;20m[2024-04-08 07:55:06,232]::[InvokeAI]::INFO -->                denoise_latents     1    10.434s     2.317G\u001b[0m\n\u001b[38;20m[2024-04-08 07:55:06,232]::[InvokeAI]::INFO -->                  core_metadata     1     0.011s     1.858G\u001b[0m\n\u001b[38;20m[2024-04-08 07:55:06,232]::[InvokeAI]::INFO -->                            l2i     1     2.477s     1.858G\u001b[0m\n\u001b[38;20m[2024-04-08 07:55:06,232]::[InvokeAI]::INFO -->               linear_ui_output     1     0.018s     0.303G\u001b[0m\n\u001b[38;20m[2024-04-08 07:55:06,232]::[InvokeAI]::INFO --> TOTAL GRAPH EXECUTION TIME:   14.429s\u001b[0m\n\u001b[38;20m[2024-04-08 07:55:06,232]::[InvokeAI]::INFO --> RAM used by InvokeAI process: 5.96G (+0.000G)\u001b[0m\n\u001b[38;20m[2024-04-08 07:55:06,232]::[InvokeAI]::INFO --> RAM used to load models: 1.99G\u001b[0m\n\u001b[38;20m[2024-04-08 07:55:06,233]::[InvokeAI]::INFO --> VRAM in use: 0.303G\u001b[0m\n\u001b[38;20m[2024-04-08 07:55:06,233]::[InvokeAI]::INFO --> RAM cache statistics:\u001b[0m\n\u001b[38;20m[2024-04-08 07:55:06,233]::[InvokeAI]::INFO -->    Model cache hits: 2\u001b[0m\n\u001b[38;20m[2024-04-08 07:55:06,233]::[InvokeAI]::INFO -->    Model cache misses: 5\u001b[0m\n\u001b[38;20m[2024-04-08 07:55:06,233]::[InvokeAI]::INFO -->    Models cached: 5\u001b[0m\n\u001b[38;20m[2024-04-08 07:55:06,233]::[InvokeAI]::INFO -->    Models cleared from cache: 0\u001b[0m\n\u001b[38;20m[2024-04-08 07:55:06,233]::[InvokeAI]::INFO -->    Cache high water mark: 1.99/7.50G\u001b[0m\n\u001b[38;20m[2024-04-08 07:55:06,536]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/e1ad49ec-9230-4f32-be90-650d35ef13be.png HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:55:06,834]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/e1ad49ec-9230-4f32-be90-650d35ef13be.png/full HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:55:06,857]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/e1ad49ec-9230-4f32-be90-650d35ef13be.png/thumbnail HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:55:07,062]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/e1ad49ec-9230-4f32-be90-650d35ef13be.png/metadata HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:57:26,348]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"POST /api/v1/queue/default/enqueue_batch HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:57:26,569]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/queue/default/status HTTP/1.1\" 200\u001b[0m\n100%|███████████████████████████████████████████| 31/31 [00:08<00:00,  3.75it/s]\n\u001b[38;20m[2024-04-08 07:57:37,240]::[InvokeAI]::INFO --> Graph stats: 0246b9ae-c855-42be-837e-47dd9e320286\u001b[0m\n\u001b[38;20m[2024-04-08 07:57:37,240]::[InvokeAI]::INFO -->                           Node   Calls  Seconds  VRAM Used\u001b[0m\n\u001b[38;20m[2024-04-08 07:57:37,240]::[InvokeAI]::INFO -->              main_model_loader     1     0.009s     0.303G\u001b[0m\n\u001b[38;20m[2024-04-08 07:57:37,240]::[InvokeAI]::INFO -->                      clip_skip     1     0.010s     0.303G\u001b[0m\n\u001b[38;20m[2024-04-08 07:57:37,240]::[InvokeAI]::INFO -->                         compel     2     0.019s     0.303G\u001b[0m\n\u001b[38;20m[2024-04-08 07:57:37,240]::[InvokeAI]::INFO -->                          noise     1     0.013s     0.303G\u001b[0m\n\u001b[38;20m[2024-04-08 07:57:37,241]::[InvokeAI]::INFO -->                denoise_latents     1     9.198s     2.082G\u001b[0m\n\u001b[38;20m[2024-04-08 07:57:37,241]::[InvokeAI]::INFO -->                  core_metadata     1     0.011s     1.623G\u001b[0m\n\u001b[38;20m[2024-04-08 07:57:37,241]::[InvokeAI]::INFO -->                            l2i     1     1.367s     1.623G\u001b[0m\n\u001b[38;20m[2024-04-08 07:57:37,241]::[InvokeAI]::INFO -->               linear_ui_output     1     0.017s     0.301G\u001b[0m\n\u001b[38;20m[2024-04-08 07:57:37,241]::[InvokeAI]::INFO --> TOTAL GRAPH EXECUTION TIME:   10.643s\u001b[0m\n\u001b[38;20m[2024-04-08 07:57:37,241]::[InvokeAI]::INFO --> RAM used by InvokeAI process: 6.35G (+0.000G)\u001b[0m\n\u001b[38;20m[2024-04-08 07:57:37,241]::[InvokeAI]::INFO --> RAM used to load models: 1.76G\u001b[0m\n\u001b[38;20m[2024-04-08 07:57:37,241]::[InvokeAI]::INFO --> VRAM in use: 0.301G\u001b[0m\n\u001b[38;20m[2024-04-08 07:57:37,241]::[InvokeAI]::INFO --> RAM cache statistics:\u001b[0m\n\u001b[38;20m[2024-04-08 07:57:37,241]::[InvokeAI]::INFO -->    Model cache hits: 3\u001b[0m\n\u001b[38;20m[2024-04-08 07:57:37,241]::[InvokeAI]::INFO -->    Model cache misses: 0\u001b[0m\n\u001b[38;20m[2024-04-08 07:57:37,242]::[InvokeAI]::INFO -->    Models cached: 5\u001b[0m\n\u001b[38;20m[2024-04-08 07:57:37,242]::[InvokeAI]::INFO -->    Models cleared from cache: 0\u001b[0m\n\u001b[38;20m[2024-04-08 07:57:37,242]::[InvokeAI]::INFO -->    Cache high water mark: 1.99/7.50G\u001b[0m\n\u001b[38;20m[2024-04-08 07:57:37,589]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/ff5cfaed-d652-4737-a2e0-1f7c3dd4aee9.png HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:57:37,916]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/ff5cfaed-d652-4737-a2e0-1f7c3dd4aee9.png/full HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:57:37,932]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/ff5cfaed-d652-4737-a2e0-1f7c3dd4aee9.png/thumbnail HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:57:38,305]::[uvicorn.access]::INFO --> 188.252.197.19:0 - \"GET /api/v1/images/i/ff5cfaed-d652-4737-a2e0-1f7c3dd4aee9.png/metadata HTTP/1.1\" 200\u001b[0m\n\u001b[38;20m[2024-04-08 07:59:10,913]::[uvicorn.error]::INFO --> connection closed\u001b[0m\n^C\n\u001b[38;20m[2024-04-08 07:59:13,711]::[uvicorn.error]::INFO --> Shutting down\u001b[0m\n\u001b[38;20m[2024-04-08 07:59:13,811]::[uvicorn.error]::INFO --> Waiting for application shutdown.\u001b[0m\n\u001b[38;20m[2024-04-08 07:59:13,812]::[uvicorn.error]::INFO --> Application shutdown complete.\u001b[0m\n\u001b[38;20m[2024-04-08 07:59:13,812]::[ModelInstallService]::INFO --> Install thread exiting\u001b[0m\n\u001b[38;20m[2024-04-08 07:59:13,812]::[uvicorn.error]::INFO --> Finished server process [553]\u001b[0m\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Clear the model in permanent storage","metadata":{}},{"cell_type":"code","source":"# Clear the permanently stored model so it can be replaced with Dreamshaper\n!rm -rf /kaggle/working/stablemodels","metadata":{"execution":{"iopub.status.busy":"2024-04-08T07:59:14.054125Z","iopub.execute_input":"2024-04-08T07:59:14.05469Z","iopub.status.idle":"2024-04-08T07:59:15.110286Z","shell.execute_reply.started":"2024-04-08T07:59:14.054633Z","shell.execute_reply":"2024-04-08T07:59:15.108972Z"},"trusted":true},"execution_count":11,"outputs":[]}]}