{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# This cell is only required if running on a TPU runtime \n","# (TPU is not supported, but the runtime can be used for the additional RAM)\n","!apt -y update \n","!apt-get -y install python3-pip\n","!unlink /usr/local/bin/python\n","!ln -s /usr/bin/python3.11 /usr/local/bin/python\n","!python --version\n","!apt -y install libgl1-mesa-glx \n","!apt -y install npm"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# Installing InvokeAI - Required\n","import os\n","import subprocess\n","\n","env = os.environ.copy()\n","\n","!pip install 'InvokeAI[xformers]' --use-pep517 --extra-index-url https://download.pytorch.org/whl/cu117 --break-system-packages\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#@markdown # Configuration and downloading default models - Required\n","\n","!mkdir /kaggle/temp/invokeai\n","!mkdir /kaggle/temp/invokeai/configs\n","\n","#@markdown Download only the default model in initial configuration.\n","#@markdown Checking this prevents running out of space in Colab.\n","\n","defaultOnly = True #@param {type:\"boolean\"}\n","skipWeights = True #@param {type:\"boolean\"}\n","skipSupportModels = False #@param {type:\"boolean\"}\n","\n","#@markdown This step usually takes about 2 minutes with only the default model and no weights.\n","\n","#@markdown You can ignore \"File exists\" warnings in the output.\n","\n","cmd = 'invokeai-configure --root_dir /kaggle/temp/invokeai --yes'\n","\n","if defaultOnly:\n","  cmd += ' --default_only'\n","\n","if skipWeights:\n","  cmd += ' --skip-sd-weights'\n","\n","if skipSupportModels:\n","  cmd += ' --skip-support-models'\n","\n","subprocess.run(cmd, shell=True, env=env)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Add the SDXL base model (optional)\n","\n","import os.path\n","from os import path\n","\n","def installSdxl(env):\n","  # Installs the SDXL base model\n","  installCmd = 'invokeai-model-install --add \"stabilityai/stable-diffusion-xl-base-1.0\" --root_dir /kaggle/temp/invokeai'\n","  subprocess.run(installCmd, shell=True, env=env)\n","  \n","alreadyInstalled = True\n","sdxlBaseSubfolderName = ''\n","modelsPath = '/kaggle/working/stablemodels/'\n","sdxlBaseSubfolderName = '/stable-diffusion-xl-base-1-0'\n","workSdxlMainFolder = modelsPath + 'sdxl/main'\n","if not path.exists(workSdxlMainFolder):\n","    os.makedirs(workSdxlMainFolder, exist_ok=True)\n","    alreadyInstalled = False\n","\n","tempModelsSdxlFolder = '/kaggle/temp/invokeai/models/sdxl/'\n","tempSdxlMainFolder = tempModelsSdxlFolder + 'main'\n","\n","subprocess.run('rm -rf ' + tempModelsSdxlFolder, shell=True, env=env)\n","if path.exists(tempModelsSdxlFolder):\n","    subprocess.run('rmdir ' + tempModelsSdxlFolder, shell=True, env=env)\n","\n","if not alreadyInstalled:\n","    if not path.exists(tempModelsSdxlFolder):\n","      os.makedirs(tempModelsSdxlFolder, exist_ok=True)\n","    subprocess.run('ln -s '+workSdxlMainFolder+' '+tempModelsSdxlFolder, shell=True, env=env)\n","    installSdxl(env)\n","else:\n","    if not path.exists(tempSdxlMainFolder):\n","      os.makedirs(tempSdxlMainFolder, exist_ok=True)\n","    subprocess.run('ln -s '+workSdxlMainFolder + sdxlBaseSubfolderName+' '+ tempSdxlMainFolder, shell=True, env=env)\n","    updateModelsYaml = True\n","    with open('/kaggle/temp/invokeai/configs/models.yaml') as f:\n","      if 'stable-diffusion-xl-base-1-0' in f.read():\n","        updateModelsYaml = False\n","    if updateModelsYaml:\n","      with open('/kaggle/temp/invokeai/configs/models.yaml', 'a') as file:\n","        lines = [\n","          'sdxl/main/stable-diffusion-xl-base-1-0:\\n',\n","          '  path: sdxl/main/stable-diffusion-xl-base-1-0\\n',\n","          '  description: Stable Diffusion XL base model (12 GB)\\n',\n","          '  variant: normal\\n',\n","          '  format: diffusers\\n'\n","        ]\n","        file.writelines(lines)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#@markdown Adding the refiner and vae (optional). This one took about 14 minutes.\n","#@markdown Skip this step if you don't need these models.\n","!invokeai-model-install --add \"stabilityai/stable-diffusion-xl-refiner-1.0\" --root_dir /kaggle/temp/invokeai --yes\n","!invokeai-model-install --add \"madebyollin/sdxl-vae-fp16-fix\" --root_dir /kaggle/temp/invokeai --yes"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Save images to the working folder (optional)\n","# If file persistance is enabled, images and the database will be saved for future sessions\n","\n","import os.path\n","from os import path\n","\n","# Linking output images to working folder\n","outputDrivePath = '/kaggle/working/images/invoke-outputs' #@param {type:\"string\"}\n","# Full path to the output folder on Google Drive\n","\n","saveDatabase = True #@param {type:\"boolean\"}\n","\n","if not outputDrivePath.endswith('/'):\n","  outputDrivePath = outputDrivePath + '/'\n","imagesDrivePath = outputDrivePath + 'images'\n","databaseDrivePath = outputDrivePath + 'databases'\n","if not path.exists(imagesDrivePath):\n","  os.makedirs(imagesDrivePath, exist_ok=True)\n","\n","\n","outputsLocalPath = '/kaggle/temp/invokeai/outputs'\n","imagesLocalPath = '/kaggle/temp/invokeai/outputs/images'\n","\n","if not path.exists(outputsLocalPath):\n","  os.makedirs(outputsLocalPath, exist_ok=True)\n","\n","import datetime\n","\n","if path.exists(imagesLocalPath):\n","    cmd = f'mv {imagesLocalPath} {imagesLocalPath}-backup{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n","    subprocess.run(cmd, shell=True, env=env)\n","\n","cmd = f'ln -s {imagesDrivePath} {outputsLocalPath}'\n","subprocess.run(cmd, shell=True, env=env)\n","\n","# Linking the database\n","if saveDatabase:\n","  if not path.exists(databaseDrivePath):\n","    os.makedirs(databaseDrivePath, exist_ok=True)\n","\n","  databaseLocalPath = '/kaggle/temp/invokeai/databases'\n","\n","  cmd = f'mv {databaseLocalPath} {databaseLocalPath}-backup{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n","  subprocess.run(cmd, shell=True, env=env)\n","\n","  cmd = f'ln -s {databaseDrivePath} /kaggle/temp/invokeai'\n","  subprocess.run(cmd, shell=True, env=env)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#@markdown # Option 1: Starting the Web UI with Localtunnel\n","\n","%cd /kaggle/temp/invokeai/\n","!npm install -g localtunnel\n","\n","#@markdown Copy the IP address shown in the output above the line\n","#@markdown \"your url is: https://some-random-words.loca.lt\"\n","!wget -q -O - ipv4.icanhazip.com\n","\n","#@markdown Wait for the line that says \"Uvicorn running on http://127.0.0.1:9090 (Press CTRL+C to quit)\"\n","\n","#@markdown Click the localtunnel url and paste the IP you copied earlier to the \"Endpoint IP\" text field\n","!lt --port 9090 --local_https False & invokeai-web  --root /kaggle/temp/invokeai/ --ignore_missing_core_models --max_vram_cache_size 14\n","\n","import gc\n","gc.collect()\n","\n","#@markdown If the UI shows a red dot that says 'disconnected' when hovered in the upper\n","#@markdown right corner and the Invoke button is disabled, change 'https' to 'http'\n","#@markdown in the browser's address bar and press enter.\n","#@markdown When the page reloads, the UI should work properly.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#@markdown # Option 2: Starting the Web UI with ngrok\n","!pip install pyngrok\n","\n","from pyngrok import ngrok, conf\n","import fileinput\n","import sys\n","\n","Ngrok_token = \"\" #@param {type:\"string\"}\n","#@markdown - Add ngrok token (obtainable from https://ngrok.com)\n","\n","#@markdown Only works with InvokeAI 3.0.2 and later\n","\n","if Ngrok_token!=\"\":\n","  ngrok.kill()\n","  srv=ngrok.connect(9090 , pyngrok_config=conf.PyngrokConfig(auth_token=Ngrok_token),\n","                    bind_tls=True).public_url\n","  print(srv)\n","  !invokeai-web --root /kaggle/temp/invokeai/ --ignore_missing_core_models\n","else:\n","  print('An ngrok token is required. You can get one on https://ngrok.com and paste it into the ngrok_token field.')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
